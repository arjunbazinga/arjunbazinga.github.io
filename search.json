[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "An engineer and researcher currently working at Woven By Toyota. My key focus areas are personalization systems, data infrastructure, and machine learning."
  },
  {
    "objectID": "about.html#woven-by-toyota",
    "href": "about.html#woven-by-toyota",
    "title": "About",
    "section": "Woven By Toyota",
    "text": "Woven By Toyota\nAt Woven, I lead multiple projects in data infrastructure, for storage (operational stores, data warehouse) and processing (ETL pipelines, scheduling, collaborative workspaces). I also developed machine learning systems for things like adaptive assessments, and course recommendation systems as one of the founding engineers of MS1, a startup(ish) focused on talent management."
  },
  {
    "objectID": "about.html#bookmyshow",
    "href": "about.html#bookmyshow",
    "title": "About",
    "section": "BookMyShow",
    "text": "BookMyShow\nPreviously, at BookMyShow, I worked on the development of real-time data pipelines for discovery and personalization systems, helping millions of users find entertainment experiences."
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html",
    "href": "posts/exerimentations-platforms/index.html",
    "title": "Experimentation Platforms",
    "section": "",
    "text": "Trustworthy Online Controlled Experiments"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#books",
    "href": "posts/exerimentations-platforms/index.html#books",
    "title": "Experimentation Platforms",
    "section": "",
    "text": "Trustworthy Online Controlled Experiments"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#resources",
    "href": "posts/exerimentations-platforms/index.html#resources",
    "title": "Experimentation Platforms",
    "section": "Resources",
    "text": "Resources\n\nTop Challenges from the first Practical Online Controlled Experiments Summit\nA/B Testing Pitfalls: Getting Numbers You Can Trust is Hard\nUSF Business Analytics Forum - Ron Kohavi\nA/B Testing at Scale: Accelerating Software Innovation\nTrustworthy Online Controlled Experiments at Large Scale\nAlways Valid Inference: Continuous Monitoring of A/B Tests"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#companies",
    "href": "posts/exerimentations-platforms/index.html#companies",
    "title": "Experimentation Platforms",
    "section": "Companies",
    "text": "Companies\n\nNetflix\n\nNetflix Articles tagged Experimentation\nIt‚Äôs All A/Bout Testing: The Netflix Experimentation Platform\nReimagining Experimentation Analysis at Netflix\nSuccess stories from a democratized experimentation platform\nKey Challenges with Quasi Experiments at Netflix\nData Compression for Large-Scale Streaming Experimentation\nPage Simulation for Better Offline Metrics at Netflix\nStreaming Video Experimentation at Netflix: Visualizing Practical and Statistical Significance\nInnovating Faster on Personalization Algorithms at Netflix Using Interleaving\n\n\n\nMicrosoft\n\nExP Experimentation Platform Accelerating software innovation through trustworthy experimentation\nOnline Experimentation at Microsoft\nExperimentation Platform\nA/B Testing and Covid-19: Data-Driven Decisions in Times of Uncertainty\nPatterns of Trustworthy Experimentation: Pre-Experiment Stage\n\n\n\nTwitter\n\nTwitter experimentation: technical overview\n\n\n\nGoogle\n\nOverlapping Experiment Infrastructure: More, Better, Faster Experimentation\n\n\n\nFacebook\n\nPlanOut is a library and interpreter for designing online experiments.\nAdaptive Experimentation Platform\n\n\n\nSpotify\n\nSpotify‚Äôs New Experimentation Platform part 1\nSpotify‚Äôs New Experimentation Platform part 2\nLarge Scale Experimentation at Spotify\n\n\n\nTinder\n\nPhoenix ‚Äî Tinder‚Äôs Testing Platform, Part ‚Äî I\nPhoenix ‚Äî Tinder‚Äôs Testing Platform ‚Äî Part II\nPhoenix ‚Äî Tinder‚Äôs Testing Platform ‚Äî Part III\n\n\n\nLinkedIn\n\nOur evolution towards T-REX: The prehistory of experimentation infrastructure at LinkedIn\nMaking the LinkedIn experimentation engine 20x faster\n\n\n\nUber\n\nUnder the Hood of Uber‚Äôs Experimentation Platform\nA/B testing at Uber: How we built a BYOM (bring your own metrics) platform\nBuilding an Intelligent Experimentation Platform with Uber Engineering\n\n\n\nAirBnB\n\n4 Principles for Making Experimentation Count\nScaling Airbnb‚Äôs Experimentation Platform\nExperiment Reporting Framework\n\n\n\nInstagram\n\nLessons Learned at Instagram Stories and Feed Machine Learning\n\n\n\nGo-Jek\n\nIntroducing Litmus: GOJEK‚Äôs Own Experimentation Platform\n\n\n\nInstaCart\n\nRandomized, controlled experiments and multivariate regression are used to continuously improve the grocery delivery engine\n\n\n\nPintrest\n\nBuilding Pinterest‚Äôs A/B testing platform"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#conferences",
    "href": "posts/exerimentations-platforms/index.html#conferences",
    "title": "Experimentation Platforms",
    "section": "Conferences",
    "text": "Conferences\n\nExperimentation Culture Awards"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#sass-solutions",
    "href": "posts/exerimentations-platforms/index.html#sass-solutions",
    "title": "Experimentation Platforms",
    "section": "SASS solutions",
    "text": "SASS solutions\n\nSplit.io\nOptimizely"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#when-you-cant-run-ab-tests",
    "href": "posts/exerimentations-platforms/index.html#when-you-cant-run-ab-tests",
    "title": "Experimentation Platforms",
    "section": "When you can‚Äôt run A/B Tests",
    "text": "When you can‚Äôt run A/B Tests\n\nQuasi Experimentation at Netflix\nKey Challenges with Quasi Experiments at Netflix\nMostly Harmless Econometrics: An Empiricist‚Äôs Companion"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#notes",
    "href": "posts/exerimentations-platforms/index.html#notes",
    "title": "Experimentation Platforms",
    "section": "Notes",
    "text": "Notes\n\n2020 CODE@MIT Experimentation platforms\n\nGaussian processes\nMulti touch attributions\nHeterogenous treatment effect\nInteraction effects\nOverlapping experiments\nWhat are potential over evaluation criteria ?\nWhat are good guardrail metrics ?\nrun A/A tests.\n\nCanary Deploys by using Experimentation platform to tell when you break guard rail metrics"
  },
  {
    "objectID": "posts/state-of-reading/index.html",
    "href": "posts/state-of-reading/index.html",
    "title": "The state of reading in 2018 and beyond.",
    "section": "",
    "text": "Audio books are seeing a resurgence, because of companies like Audible.\nText to speech is good, and is getting better .\nWireless Bluetooth earphones are becoming common place, the increase in convenience and battery life allows people to have them on longer.\nUnlike content that you have to watch/read, you can work on other stuff while you listen.\nI see a time where we can listen to most of the things we read.\nCreates a whole new kind of medium.\nNews, blog posts and Stories most affected.\nMost of the speech generated by machines.\nMost of the classic texts available for free on the internet.\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/course-schedule-generator/index.html",
    "href": "posts/course-schedule-generator/index.html",
    "title": "Course Schedule Generator",
    "section": "",
    "text": "A website which allows students of IIT Indore to add courses they are interested in to their calendar.\nI was tired of doing this manually every time.\nUse it here\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/multi-armed-bandits/multi-armed-bandits.html",
    "href": "posts/multi-armed-bandits/multi-armed-bandits.html",
    "title": "Multi Armed Bandits",
    "section": "",
    "text": "Imagine you are at a casino, and you have N slot machines to play, each slot machine gives rewards according to a fixed probability distribution. What strategy should you play with to maximise your total reward ?\nThis problem is known as Multi Armed Bandit problem.\n\n# Importing numpy for math, and matplotlib for plots\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline"
  },
  {
    "objectID": "posts/multi-armed-bandits/multi-armed-bandits.html#problem",
    "href": "posts/multi-armed-bandits/multi-armed-bandits.html#problem",
    "title": "Multi Armed Bandits",
    "section": "",
    "text": "Imagine you are at a casino, and you have N slot machines to play, each slot machine gives rewards according to a fixed probability distribution. What strategy should you play with to maximise your total reward ?\nThis problem is known as Multi Armed Bandit problem.\n\n# Importing numpy for math, and matplotlib for plots\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline"
  },
  {
    "objectID": "posts/multi-armed-bandits/multi-armed-bandits.html#arms",
    "href": "posts/multi-armed-bandits/multi-armed-bandits.html#arms",
    "title": "Multi Armed Bandits",
    "section": "Arms",
    "text": "Arms\nAn arm when pulled, gives a random number from a normal distribution with fixed mean(mu) and deviation(sigma). When pulled many times the frequency of the rewards look like this:\n X axis is the magnitude of reward\nY axis is it‚Äôs frequency.\nThe Arm class provides an arm with these properties.\n\nclass Arm:\n\n    def __init__(self, mu=None, sigma=None):\n        if mu is None:\n            self.mu = np.absolute(np.random.uniform())\n        else:\n            self.mu = mu\n        \n        \n        if sigma is None:\n            self.sigma=np.absolute(np.random.uniform())\n        else:\n            self.sigma = sigma\n\n\n    def pull(self):\n        reward = np.random.normal(self.mu, self.sigma, 1)\n        return reward\n\n\ndef get_arms(k):\n    # returns a list of arms\n    arms = []\n    for i in range(k):\n        arms.append(Arm())\n    return arms"
  },
  {
    "objectID": "posts/multi-armed-bandits/multi-armed-bandits.html#agents",
    "href": "posts/multi-armed-bandits/multi-armed-bandits.html#agents",
    "title": "Multi Armed Bandits",
    "section": "Agents",
    "text": "Agents\nAn agent here is a player who pulls arms to play. It has a policy, which is a list of probabilities associated with each arm.\nThe agent class makes designing agents fast. The object is initialised with arms and whether it should play all arms once as part of the initialisation.\nFeatures provided by this class:\nAttributes: * expectations[i]: gives the expected reward on playing arm[i] * times_played[i]: gives the number of times the agent has played arm[i] * N = Total number of times agent has played * reward_history : list of rewards earned by the agent * choice_history : list of choices made by the agent\nMethods: * gamble(i): Plays for i iterations while updating it‚Äôs policy. * play(i): Pulls arm[i] and updates reward_history, N , times_played * select_arm(): returns index of an arm by sampling probability distribution given by the policy\n\nclass agent:\n    def __init__(self, arms, play_once=1):\n        self.expectations = np.zeros(len(arms))\n        self.times_played = np.zeros(len(arms))\n        self.arms = arms\n\n        self.number_of_arms = len(arms)\n        self.N = 0\n\n        self.reward_history = []\n        self.choice_history = []\n\n        if play_once == 1:\n            for i in range(self.number_of_arms):\n                self.expectations[i] = self.play(i)\n\n    def play(self, index):\n        reward = self.arms[index].pull()\n\n        self.times_played[index] += 1\n        self.N += 1\n\n        self.choice_history.append(index)\n        self.reward_history.append(reward)\n\n        return reward\n\n    def policy(self):\n        pass\n\n    def update_expectations(self, reward, index):\n        self.expectations[index] += (reward - self.expectations[index])/self.N\n\n    def select_arm(self):\n        options = range(self.number_of_arms)\n        i = np.random.choice(options, p=self.policy(), replace=False)\n        return i\n\n    def gamble(self, iterations):\n        for i in range(iterations):\n            index = self.select_arm()\n            reward = self.play(index)\n            self.update_expectations(reward, index)\n\n\nExample agents\nTo make a new agent we inherit the agent class.\nTime to make some agents!\n\n\nFirst up: epsilon-greedy\nThis agent plays the arm with the highest expected reward with 1 - epsilon probability, and plays a random arm with epsilon probability\nSo\nepsilon = 1 =&gt; random choices\nepsilon = 0 =&gt; greedy choices\n\nclass epsilon_greedy(agent):\n\n    def __init__(self, arms, play_once=1, epsilon=0.1):\n        super().__init__(arms, play_once)\n        self.epsilon = epsilon\n        \n    def __str__(self):\n        return \"Epsilon-Greedy Agent, epsilon= \"+str(self.epsilon)\n    \n    def policy(self):\n        temp = np.zeros_like(self.expectations)\n        temp[np.argmax(self.expectations)] = 1-self.epsilon\n        ans = temp + self.epsilon/self.number_of_arms\n        return ans\n\n\n\nBeta-Softmax\nThis agent plays an arm[i] with probability proportional to: e^(expected_reward(arm[i])/beta)\nWe normalise the whole thing by the sum over all the arms.\n\nclass softmax(agent):\n\n    def __init__(self, arms, play_once=1, beta=1):\n        super().__init__(arms, play_once)\n        self.beta = beta\n        \n    def __str__(self):\n        return \"Softmax agent, beta= \"+ str(self.beta)\n\n    def policy(self):\n        temp = np.exp(self.expectations/self.beta)\n        ans = temp / np.sum(temp, axis=0)\n        return ans\n\n\n\nUpper Confidence Bound (UCB1)\nUCB1 agent plays the arm with the highest metric, where metric of arm i is : metric[i] = expected_reward[i] + sqrt(2*log(N)/times_played[i])\nNote Best peformance when rewards are between 0 and 1\n\nclass ucb(agent):\n\n    def __init__(self, arms, play_once=1):\n        super().__init__(arms, play_once)\n\n    def __str__(self):\n        return \"UCB1 agent\"\n    \n    def policy(self):\n        temp = self.expectations + np.sqrt(2*np.log(self.N)/self.times_played)\n        ans = np.zeros_like(temp)\n        ans[np.argmax(temp)] = 1\n        return ans"
  },
  {
    "objectID": "posts/multi-armed-bandits/multi-armed-bandits.html#metrics",
    "href": "posts/multi-armed-bandits/multi-armed-bandits.html#metrics",
    "title": "Multi Armed Bandits",
    "section": "Metrics",
    "text": "Metrics\nMetric : A scalar number, makes comparison easier.\nTo compare the performance of our agents we can use these metrics\n\navg_reward[i] : this gives the average reward till i+1 iteration.\nmax_reward : this tells us the maximum expected reward\neuclid_distance : we can think of as learnt policy and optimal policy as vectors and compute the distance between them , smaller is better\ncosine_simmilarity : compute the cos(q) between the policies. larger is better\n\n\ndef maxreward(arms):\n    #Max rewards\n    a= [arm.mu for arm in arms]\n    return max(a)\n\ndef avg_reward(rewards):\n    ans = []\n    ans.append(rewards[0])\n    for i in range(1,len(rewards)):\n        ans.append(ans[i-1]+rewards[i])\n    for i in range(len(ans)):\n        ans[i]/=i+1\n    return ans\n\ndef cosine_similarity(a,b):\n    temp = a*b\n    temp/=(euclid_distance(a)* euclid_distance(b))\n    return np.sum(temp, axis=0)\n    \ndef euclid_distance(a):\n    return np.sqrt(np.sum(a*a, axis=0))\n\n\nTest\nThis function takes a list of agents and the number of iterations. Makes each agent play, and prints its metrics.\n\ndef test(agents, iterations):\n    for agent in agents:\n        \n        agent.gamble(iterations)\n        \n        temp = [ arm.mu for arm in levers] \n        optimal_policy = np.zeros_like(agent.expectations)\n        optimal_policy[temp.index(max(temp))] = 1\n        \n        avg_rewards_earned = avg_reward(agent.reward_history)\n        \n        print(agent)\n        print(\"maximum possible reward:\", maxreward(levers))\n        print(\"average reward:\", avg_rewards_earned[-1])\n        print(\"cosine similarity\" ,cosine_similarity(agent.policy(), optimal_policy))\n        euclid_norm = euclid_distance(agent.policy()-optimal_policy)/len(optimal_policy)\n        print(\"euclidian norm \",euclid_norm)\n        \n        \n        plt.plot(avg_rewards_earned)\n        plt.ylabel('Average Reward')\n        plt.xlabel('Iteration')\n        plt.show()\n        print(\"\\n\")\n    \n        # print(\"optimal policy:\" , optimal)\n        # print(\"learnt policy:\" ,agent.policy())\n        \n    \n        \n        # plt.scatter(range(len(agent.choice_history)),y=agent.choice_history)\n        # plt.title(\"Choices\")\n        # plt.xlabel(\"time\")\n        # plt.ylabel(\"arm\")\n        # plt.show()\n        # print(\"\\n\")\n    \n    \n\n\nlevers = get_arms(10)\n\nagents = [\n    epsilon_greedy(levers, epsilon=1),\n    epsilon_greedy(levers, epsilon=0),\n    softmax(levers, beta=0.1),\n    ucb(levers)\n\n]\n\n\nplt.plot([ arm.mu for arm in levers] )\nplt.title(\"distribution of expected value of arms\")\n\nText(0.5, 1.0, 'distribution of expected value of arms')\n\n\n\n\n\n\n\n\n\n\ntest(agents, 5000)\n\nEpsilon-Greedy Agent, epsilon= 1\nmaximum possible reward: 0.9851042878107023\naverage reward: [0.47962497]\ncosine similarity 0.3162277660168379\neuclidian norm  0.09486832980505139\n\n\n\n\n\n\n\n\n\n\n\nEpsilon-Greedy Agent, epsilon= 0\nmaximum possible reward: 0.9851042878107023\naverage reward: [0.98686237]\ncosine similarity 1.0\neuclidian norm  0.0\n\n\n\n\n\n\n\n\n\n\n\nSoftmax agent, beta= 0.1\nmaximum possible reward: 0.9851042878107023\naverage reward: [0.91348264]\ncosine similarity 0.9992727823574249\neuclidian norm  0.008915931500017809\n\n\n\n\n\n\n\n\n\n\n\nUCB1 agent\nmaximum possible reward: 0.9851042878107023\naverage reward: [0.89258379]\ncosine similarity 0.0\neuclidian norm  0.1414213562373095\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperimental stuff:\nBelow are a few agents I wrote for fun.\n\n\nclass softmax_with_exponentiation(agent):\n\n    def __init__(self, arms, play_once=1, beta=1, exp=1):\n        super().__init__(arms, play_once)\n        self.beta = beta\n        self.exp = exp\n\n    def policy(self):\n        temp = np.exp(self.expectations/self.beta)\n        ans = temp / np.sum(temp, axis=0)\n        ans = ans**self.exp\n        ans /= np.sum(ans, axis=0)\n        return ans\n\n\nclass softmax_with_reccurence(agent):\n\n    def __init__(self, arms, play_once=1, beta=1):\n        super().__init__(arms, play_once)\n        self.old_policy = np.ones_like(self.expectations)/self.l\n        self.beta = beta\n\n    def policy(self):\n        temp = np.exp(self.expectations/self.beta)\n        new_policy = temp / np.sum(temp, axis=0)\n\n        result = np.multiply(new_policy, self.old_policy)\n        result /= np.sum(result, axis=0)\n        self.old_policy = result\n\n        return result\n\n\nclass greedy_with_reccurence(agent):\n    # alpha = number &lt; 1; will sum over a number of observations and will keep\n    # osiclating.\n    # alpha = N will allow the algo to converge to an arm, greedy doesn't\n    # really need this, kind of always give one answer.\n\n    def __init__(self, arms, play_once=1, alpha=1):\n        super().__init__(arms, play_once)\n        self.old_policy = np.ones_like(self.expectations)\n        self.alpha = alpha\n\n    def policy(self):\n        new_policy = np.zeros_like(self.expectations)\n        new_policy[np.argmax(self.expectations)] = 1\n\n        new_policy = (1-self.alpha)*new_policy + self.alpha*self.old_policy\n\n        new_policy /= np.sum(new_policy, axis=0)\n        self.old_policy = new_policy\n\n        return new_policy\n\n# class magic(agent):\n#    def __init__(self, arms, play_once=1, exp=1):\n#        super().__init__(arms, play_once)\n#        self.old_policy = np.ones_like(self.expectations)/self.l\n#        self.exp = exp\n#\n#    def policy(self):\n#        new_policy = f(old_policy, g(expectations))"
  },
  {
    "objectID": "posts/jargonizer/index.html",
    "href": "posts/jargonizer/index.html",
    "title": "Jargonizer",
    "section": "",
    "text": "Jargonizer\nWhat if instead of aiming for clarity and conciesness, our goal was to make our sentences as unweildy and hard to understand as possible?\nA simple way to do this is to replace easy to understand phrases with harder ones. Wikipedia maintains1 one such list for us. Here is the website I made so you can play with it online as well, it all runs in your browser, no text is sent to a server.\nReading at the output generated from this, I can‚Äôt help but feel like I am reading a legal document."
  },
  {
    "objectID": "posts/jargonizer/index.html#footnotes",
    "href": "posts/jargonizer/index.html#footnotes",
    "title": "Jargonizer",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nUsed to ü•≤‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/mental-health-checklist/index.html",
    "href": "posts/mental-health-checklist/index.html",
    "title": "Mental Health Checklists",
    "section": "",
    "text": "Some quizes I made so it‚Äôs easy to keep track of mental health.\n\nBurn‚Äôs depression Checklist use it here\nNovaco‚Äôs Anger Scale use it here\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/friend-or-foe/index.html",
    "href": "posts/friend-or-foe/index.html",
    "title": "Friend Or Foe",
    "section": "",
    "text": "Co-opeartive and Adversarial Environments\n\n\nThis is a mini interactive ‚Äúgame‚Äù, I made inspired by the paper, without giving too much away, I urge you to play.\nAI Safety Grid Worlds,\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/learning-machine-learning/index.html",
    "href": "posts/learning-machine-learning/index.html",
    "title": "Learning Machine Learning",
    "section": "",
    "text": "This post will talk about how I‚Äôm going about learning machine learning.\nMostly online content.\n\nPodcasts\nThese podcasts are amazing,and what got me interested in the first place. Get a podcast app, I love podcast addict (android). Some awesome podcasts:\n* Partially Derivative * Linear Digressions * Data Skeptic\nSome that are supposed to be good but never tried: * Not so standard deviations * Data science at home * Talking machines\n\n\nOnline Courses\nA few awesome courses.\n\nAndrew Ng Coursera\nA good first course, which teaches you bottom up, from basics to advanced techniques. Matlab/Octave.\nFast.ai\nA course which aims to teach by coding, and takes a top down approach.\n\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/newbie-quiz/index.html",
    "href": "posts/newbie-quiz/index.html",
    "title": "Newbie quiz",
    "section": "",
    "text": "Newbie Quiz\n\n\nIndraneel and I had prepared this quiz as a way of introducting quizzing to new people and narrowing down potential recruits. The quiz covers a broad range of topics, from pop culture, sports, technology, politics\nLots of fun!\n\nQuestions\nGet the questions.\n\n\nAnswers\nGet the answers.\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/game-of-thrones-quiz/index.html",
    "href": "posts/game-of-thrones-quiz/index.html",
    "title": "Game Of Thrones quiz",
    "section": "",
    "text": "Game Of Thrones Quiz\nThis quiz was created as part of cultural week, right as Game of Thrones season 7 ended.\nIt is broken into 3 seperate rounds"
  },
  {
    "objectID": "posts/game-of-thrones-quiz/index.html#first-round",
    "href": "posts/game-of-thrones-quiz/index.html#first-round",
    "title": "Game Of Thrones quiz",
    "section": "First round",
    "text": "First round\nQuestions\nAnswers"
  },
  {
    "objectID": "posts/game-of-thrones-quiz/index.html#second-round",
    "href": "posts/game-of-thrones-quiz/index.html#second-round",
    "title": "Game Of Thrones quiz",
    "section": "Second round",
    "text": "Second round\nSlides\nvideo for question 1\nmusic for question 2\nvideo for question 3"
  },
  {
    "objectID": "posts/game-of-thrones-quiz/index.html#third-round",
    "href": "posts/game-of-thrones-quiz/index.html#third-round",
    "title": "Game Of Thrones quiz",
    "section": "Third round",
    "text": "Third round\nConnect"
  },
  {
    "objectID": "posts/harry-potter-quiz/index.html",
    "href": "posts/harry-potter-quiz/index.html",
    "title": "Harry Potter quiz",
    "section": "",
    "text": "Pottermania 2018\n\n\nThe goal of the is to be something easy that anybody with little experience in quizzing can take part in. created with Bitan, and Keyur as part of Quiz club.\n\nQuestions\nGet the questions.\nGet the video for question number 14\nGet the Music for question number 20\n\n\nAnswers\nGet the answers.\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/about-this-website/index.html",
    "href": "posts/about-this-website/index.html",
    "title": "About this website",
    "section": "",
    "text": "This post is a bit of a meta post about arjunsriva.com\nA lot of my thinking on personal websites has been influenced by other great websites like Gwern‚Äôs, please read this if you‚Äôre interested in it.\nMy goals for this websites are:\n\nTo share things I learned that I personally found useful\nTo provide a playground for me to flesh out rough ideas and speculate.\nTo help me increase the clarity of my thinking by the act of writing something out.\n\non the implementation side my goals are\n\nMake it easy for me to never lose data\n\nmost writing is stored as simple text files, version controlled by git\n\nMake it easy to mix code and prose to explain certain concepts\n\nSome things that I plan on implementing later as I write more are:\n\nAutomatic link archiving to prevent link rot\nConfidence tags to show how certain I am of different things\nBetter sections / tagging to differentiate different kinds of posts, eg. reading list and notes\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/infant-mortality/index.html",
    "href": "posts/infant-mortality/index.html",
    "title": "Infant Mortality In India",
    "section": "",
    "text": "I thought about this after reading Doing good better.\nSoon after I found out about kepler.gl which made this the perfect project to test it out.\nI extracted the data I needed for my analysis from a PDF of an annual summary report by the Government of India, available here, as I couldn‚Äôt find a comprehensive and user-friendly source.\nYou can read the analysis here.\nHere is the kepler.gl map I created for this analysis.\nIt contains the following layers:\n\nTotal Lives Lost: The number of infants who died in each state. The height of each region is proportional to the number of lives lost, with redder regions having a higher infant mortality rate.\nTotal Population : The population of each state. The height of each region is proportional to the population, with bluer regions having a higher birth rate.\nTotal Lives Lost Rural: The same as Total Lives Lost, but only for rural areas in each state.\nTotal Lives Lost Urban: The same as Total Lives Lost, but only for urban areas in each state.\n\nOnce the map loads you can click on the layers on the right to toggle them on and off. You can also click on the layers to see the data for each region.\nThe json file for the map is available here.\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nExperimentation Platforms\n\n\n\n\n\n\nExperimentation\n\n\n\nAn Overview of Experimentation Platforms.\n\n\n\n\n\nMar 21, 2021\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nCourse Schedule Generator\n\n\n\n\n\n\nIIT Indore\n\n\n\nA website which adds courses to your personal calendar, for students of IIT Indore.\n\n\n\n\n\nJan 8, 2020\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nHarry Potter quiz\n\n\n\n\n\n\nIIT Indore\n\n\nQuiz\n\n\n\nA beginner friendly quiz on the wizarding world\n\n\n\n\n\nAug 26, 2018\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nThe state of reading in 2018 and beyond.\n\n\n\n\n\n\nFuture\n\n\n\n\n\n\n\n\n\nAug 5, 2018\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nFriend Or Foe\n\n\n\n\n\n\nAI\n\n\nProjects\n\n\n\nAn interactive game inspired by the paper ‚ÄúAI Safety Grid Worlds‚Äù\n\n\n\n\n\nJul 28, 2018\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nInfant Mortality In India\n\n\n\n\n\n\nAnalysis\n\n\n\nAn analysis of infant mortality rates across India.\n\n\n\n\n\nJun 15, 2018\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nJargonizer\n\n\n\n\n\n\nProjects\n\n\n\nGenerate sentences that nobody can read.\n\n\n\n\n\nJun 12, 2018\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Machine Learning\n\n\n\n\n\n\nAI\n\n\n\n\n\n\n\n\n\nNov 12, 2017\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nMulti Armed Bandits\n\n\n\n\n\n\nAI\n\n\n\nor how to balance exploration and exploitation more formally\n\n\n\n\n\nNov 12, 2017\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nGame Of Thrones quiz\n\n\n\n\n\n\nIIT Indore\n\n\nQuiz\n\n\n\nA quiz made for cultural week\n\n\n\n\n\nSep 4, 2017\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nNewbie quiz\n\n\n\n\n\n\nIIT Indore\n\n\nQuiz\n\n\n\nA quiz to introduce quizzing to new people and narrowing down potential recruits.\n\n\n\n\n\nAug 20, 2017\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nMental Health Checklists\n\n\n\n\n\n\nProjects\n\n\n\nA website which allows quick tracking of mental health.\n\n\n\n\n\nJan 8, 2017\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nAbout this website\n\n\n\n\n\n\nMeta\n\n\n\na meta post about this website\n\n\n\n\n\nJan 1, 2016\n\n\nArjun Srivastava\n\n\n\n\n\n\nNo matching items"
  }
]