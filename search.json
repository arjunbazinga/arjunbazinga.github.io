[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nExperimentation Platforms\n\n\n\n\n\n\nExperimentation\n\n\n\nAn Overview of Experimentation Platforms.\n\n\n\n\n\nMar 21, 2021\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nCourse Schedule Generator\n\n\n\n\n\n\nIIT Indore\n\n\n\nA website which adds courses to your personal calendar, for students of IIT Indore.\n\n\n\n\n\nJan 8, 2020\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nHarry Potter quiz\n\n\n\n\n\n\nIIT Indore\n\n\nQuiz\n\n\n\nA beginner friendly quiz on the wizarding world\n\n\n\n\n\nAug 26, 2018\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nThe state of reading in 2018 and beyond.\n\n\n\n\n\n\nFuture\n\n\n\n\n\n\n\n\n\nAug 5, 2018\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nFriend Or Foe\n\n\n\n\n\n\nAI\n\n\nProjects\n\n\n\nAn interactive game inspired by the paper ‚ÄúAI Safety Grid Worlds‚Äù\n\n\n\n\n\nJul 28, 2018\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nInfant Mortality In India\n\n\n\n\n\n\nAnalysis\n\n\n\nAn analysis of infant mortality rates across India.\n\n\n\n\n\nJun 15, 2018\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nJargonizer\n\n\n\n\n\n\nProjects\n\n\n\nGenerate sentences that nobody can read.\n\n\n\n\n\nJun 12, 2018\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nMulti Armed Bandits\n\n\n\n\n\n\nAI\n\n\n\nor how to balance exploration and exploitation more formally\n\n\n\n\n\nNov 12, 2017\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Machine Learning\n\n\n\n\n\n\nAI\n\n\n\n\n\n\n\n\n\nNov 12, 2017\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nGame Of Thrones quiz\n\n\n\n\n\n\nIIT Indore\n\n\nQuiz\n\n\n\nA quiz made for cultural week\n\n\n\n\n\nSep 4, 2017\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nNewbie quiz\n\n\n\n\n\n\nIIT Indore\n\n\nQuiz\n\n\n\nA quiz to introduce quizzing to new people and narrowing down potential recruits.\n\n\n\n\n\nAug 20, 2017\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nMental Health Checklists\n\n\n\n\n\n\nProjects\n\n\n\nA website which allows quick tracking of mental health.\n\n\n\n\n\nJan 8, 2017\n\n\nArjun Srivastava\n\n\n\n\n\n\n\n\n\n\n\n\nAbout this website\n\n\n\n\n\n\nMeta\n\n\n\na meta post about this website\n\n\n\n\n\nJan 1, 2016\n\n\nArjun Srivastava\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/infant-mortality/index.html",
    "href": "posts/infant-mortality/index.html",
    "title": "Infant Mortality In India",
    "section": "",
    "text": "I thought about this after reading Doing good better.\nSoon after I found out about kepler.gl which made this the perfect project to test it out.\nI extracted the data I needed for my analysis from a PDF of an annual summary report by the Government of India, available here, as I couldn‚Äôt find a comprehensive and user-friendly source.\nYou can read the analysis here.\nHere is the kepler.gl map I created for this analysis.\nIt contains the following layers:\n\nTotal Lives Lost: The number of infants who died in each state. The height of each region is proportional to the number of lives lost, with redder regions having a higher infant mortality rate.\nTotal Population : The population of each state. The height of each region is proportional to the population, with bluer regions having a higher birth rate.\nTotal Lives Lost Rural: The same as Total Lives Lost, but only for rural areas in each state.\nTotal Lives Lost Urban: The same as Total Lives Lost, but only for urban areas in each state.\n\nOnce the map loads you can click on the layers on the right to toggle them on and off. You can also click on the layers to see the data for each region.\nThe json file for the map is available here.\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/jargonizer/index.html",
    "href": "posts/jargonizer/index.html",
    "title": "Jargonizer",
    "section": "",
    "text": "Jargonizer\nWhat if instead of aiming for clarity and conciesness, our goal was to make our sentences as unweildy and hard to understand as possible?\nA simple way to do this is to replace easy to understand phrases with harder ones. Wikipedia maintains1 one such list for us. Here is the website I made so you can play with it online as well, it all runs in your browser, no text is sent to a server.\nReading at the output generated from this, I can‚Äôt help but feel like I am reading a legal document."
  },
  {
    "objectID": "posts/jargonizer/index.html#footnotes",
    "href": "posts/jargonizer/index.html#footnotes",
    "title": "Jargonizer",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nUsed to ü•≤‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/multi-armed-bandits/multi-armed-bandits.html",
    "href": "posts/multi-armed-bandits/multi-armed-bandits.html",
    "title": "Multi Armed Bandits",
    "section": "",
    "text": "Imagine you are at a casino, and you have N slot machines to play, each slot machine gives rewards according to a fixed probability distribution. What strategy should you play with to maximise your total reward ?\nThis problem is known as Multi Armed Bandit problem.\n\n# Importing numpy for math, and matplotlib for plots\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline"
  },
  {
    "objectID": "posts/multi-armed-bandits/multi-armed-bandits.html#problem",
    "href": "posts/multi-armed-bandits/multi-armed-bandits.html#problem",
    "title": "Multi Armed Bandits",
    "section": "",
    "text": "Imagine you are at a casino, and you have N slot machines to play, each slot machine gives rewards according to a fixed probability distribution. What strategy should you play with to maximise your total reward ?\nThis problem is known as Multi Armed Bandit problem.\n\n# Importing numpy for math, and matplotlib for plots\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline"
  },
  {
    "objectID": "posts/multi-armed-bandits/multi-armed-bandits.html#arms",
    "href": "posts/multi-armed-bandits/multi-armed-bandits.html#arms",
    "title": "Multi Armed Bandits",
    "section": "Arms",
    "text": "Arms\nAn arm when pulled, gives a random number from a normal distribution with fixed mean(mu) and deviation(sigma). When pulled many times the frequency of the rewards look like this:\n X axis is the magnitude of reward\nY axis is it‚Äôs frequency.\nThe Arm class provides an arm with these properties.\n\nclass Arm:\n\n    def __init__(self, mu=None, sigma=None):\n        if mu is None:\n            self.mu = np.absolute(np.random.uniform())\n        else:\n            self.mu = mu\n        \n        \n        if sigma is None:\n            self.sigma=np.absolute(np.random.uniform())\n        else:\n            self.sigma = sigma\n\n\n    def pull(self):\n        reward = np.random.normal(self.mu, self.sigma, 1)\n        return reward\n\n\ndef get_arms(k):\n    # returns a list of arms\n    arms = []\n    for i in range(k):\n        arms.append(Arm())\n    return arms"
  },
  {
    "objectID": "posts/multi-armed-bandits/multi-armed-bandits.html#agents",
    "href": "posts/multi-armed-bandits/multi-armed-bandits.html#agents",
    "title": "Multi Armed Bandits",
    "section": "Agents",
    "text": "Agents\nAn agent here is a player who pulls arms to play. It has a policy, which is a list of probabilities associated with each arm.\nThe agent class makes designing agents fast. The object is initialised with arms and whether it should play all arms once as part of the initialisation.\nFeatures provided by this class:\nAttributes: * expectations[i]: gives the expected reward on playing arm[i] * times_played[i]: gives the number of times the agent has played arm[i] * N = Total number of times agent has played * reward_history : list of rewards earned by the agent * choice_history : list of choices made by the agent\nMethods: * gamble(i): Plays for i iterations while updating it‚Äôs policy. * play(i): Pulls arm[i] and updates reward_history, N , times_played * select_arm(): returns index of an arm by sampling probability distribution given by the policy\n\nclass agent:\n    def __init__(self, arms, play_once=1):\n        self.expectations = np.zeros(len(arms))\n        self.times_played = np.zeros(len(arms))\n        self.arms = arms\n\n        self.number_of_arms = len(arms)\n        self.N = 0\n\n        self.reward_history = []\n        self.choice_history = []\n\n        if play_once == 1:\n            for i in range(self.number_of_arms):\n                self.expectations[i] = self.play(i)\n\n    def play(self, index):\n        reward = self.arms[index].pull()\n\n        self.times_played[index] += 1\n        self.N += 1\n\n        self.choice_history.append(index)\n        self.reward_history.append(reward)\n\n        return reward\n\n    def policy(self):\n        pass\n\n    def update_expectations(self, reward, index):\n        self.expectations[index] += (reward - self.expectations[index])/self.N\n\n    def select_arm(self):\n        options = range(self.number_of_arms)\n        i = np.random.choice(options, p=self.policy(), replace=False)\n        return i\n\n    def gamble(self, iterations):\n        for i in range(iterations):\n            index = self.select_arm()\n            reward = self.play(index)\n            self.update_expectations(reward, index)\n\n\nExample agents\nTo make a new agent we inherit the agent class.\nTime to make some agents!\n\n\nFirst up: epsilon-greedy\nThis agent plays the arm with the highest expected reward with 1 - epsilon probability, and plays a random arm with epsilon probability\nSo\nepsilon = 1 =&gt; random choices\nepsilon = 0 =&gt; greedy choices\n\nclass epsilon_greedy(agent):\n\n    def __init__(self, arms, play_once=1, epsilon=0.1):\n        super().__init__(arms, play_once)\n        self.epsilon = epsilon\n        \n    def __str__(self):\n        return \"Epsilon-Greedy Agent, epsilon= \"+str(self.epsilon)\n    \n    def policy(self):\n        temp = np.zeros_like(self.expectations)\n        temp[np.argmax(self.expectations)] = 1-self.epsilon\n        ans = temp + self.epsilon/self.number_of_arms\n        return ans\n\n\n\nBeta-Softmax\nThis agent plays an arm[i] with probability proportional to: e^(expected_reward(arm[i])/beta)\nWe normalise the whole thing by the sum over all the arms.\n\nclass softmax(agent):\n\n    def __init__(self, arms, play_once=1, beta=1):\n        super().__init__(arms, play_once)\n        self.beta = beta\n        \n    def __str__(self):\n        return \"Softmax agent, beta= \"+ str(self.beta)\n\n    def policy(self):\n        temp = np.exp(self.expectations/self.beta)\n        ans = temp / np.sum(temp, axis=0)\n        return ans\n\n\n\nUpper Confidence Bound (UCB1)\nUCB1 agent plays the arm with the highest metric, where metric of arm i is : metric[i] = expected_reward[i] + sqrt(2*log(N)/times_played[i])\nNote Best peformance when rewards are between 0 and 1\n\nclass ucb(agent):\n\n    def __init__(self, arms, play_once=1):\n        super().__init__(arms, play_once)\n\n    def __str__(self):\n        return \"UCB1 agent\"\n    \n    def policy(self):\n        temp = self.expectations + np.sqrt(2*np.log(self.N)/self.times_played)\n        ans = np.zeros_like(temp)\n        ans[np.argmax(temp)] = 1\n        return ans"
  },
  {
    "objectID": "posts/multi-armed-bandits/multi-armed-bandits.html#metrics",
    "href": "posts/multi-armed-bandits/multi-armed-bandits.html#metrics",
    "title": "Multi Armed Bandits",
    "section": "Metrics",
    "text": "Metrics\nMetric : A scalar number, makes comparison easier.\nTo compare the performance of our agents we can use these metrics\n\navg_reward[i] : this gives the average reward till i+1 iteration.\nmax_reward : this tells us the maximum expected reward\neuclid_distance : we can think of as learnt policy and optimal policy as vectors and compute the distance between them , smaller is better\ncosine_simmilarity : compute the cos(q) between the policies. larger is better\n\n\ndef maxreward(arms):\n    #Max rewards\n    a= [arm.mu for arm in arms]\n    return max(a)\n\ndef avg_reward(rewards):\n    ans = []\n    ans.append(rewards[0])\n    for i in range(1,len(rewards)):\n        ans.append(ans[i-1]+rewards[i])\n    for i in range(len(ans)):\n        ans[i]/=i+1\n    return ans\n\ndef cosine_similarity(a,b):\n    temp = a*b\n    temp/=(euclid_distance(a)* euclid_distance(b))\n    return np.sum(temp, axis=0)\n    \ndef euclid_distance(a):\n    return np.sqrt(np.sum(a*a, axis=0))\n\n\nTest\nThis function takes a list of agents and the number of iterations. Makes each agent play, and prints its metrics.\n\ndef test(agents, iterations):\n    for agent in agents:\n        \n        agent.gamble(iterations)\n        \n        temp = [ arm.mu for arm in levers] \n        optimal_policy = np.zeros_like(agent.expectations)\n        optimal_policy[temp.index(max(temp))] = 1\n        \n        avg_rewards_earned = avg_reward(agent.reward_history)\n        \n        print(agent)\n        print(\"maximum possible reward:\", maxreward(levers))\n        print(\"average reward:\", avg_rewards_earned[-1])\n        print(\"cosine similarity\" ,cosine_similarity(agent.policy(), optimal_policy))\n        euclid_norm = euclid_distance(agent.policy()-optimal_policy)/len(optimal_policy)\n        print(\"euclidian norm \",euclid_norm)\n        \n        \n        plt.plot(avg_rewards_earned)\n        plt.ylabel('Average Reward')\n        plt.xlabel('Iteration')\n        plt.show()\n        print(\"\\n\")\n    \n        # print(\"optimal policy:\" , optimal)\n        # print(\"learnt policy:\" ,agent.policy())\n        \n    \n        \n        # plt.scatter(range(len(agent.choice_history)),y=agent.choice_history)\n        # plt.title(\"Choices\")\n        # plt.xlabel(\"time\")\n        # plt.ylabel(\"arm\")\n        # plt.show()\n        # print(\"\\n\")\n    \n    \n\n\nlevers = get_arms(10)\n\nagents = [\n    epsilon_greedy(levers, epsilon=1),\n    epsilon_greedy(levers, epsilon=0),\n    softmax(levers, beta=0.1),\n    ucb(levers)\n\n]\n\n\nplt.plot([ arm.mu for arm in levers] )\nplt.title(\"distribution of expected value of arms\")\n\nText(0.5, 1.0, 'distribution of expected value of arms')\n\n\n\n\n\n\n\n\n\n\ntest(agents, 5000)\n\nEpsilon-Greedy Agent, epsilon= 1\nmaximum possible reward: 0.9851042878107023\naverage reward: [0.47962497]\ncosine similarity 0.3162277660168379\neuclidian norm  0.09486832980505139\n\n\n\n\n\n\n\n\n\n\n\nEpsilon-Greedy Agent, epsilon= 0\nmaximum possible reward: 0.9851042878107023\naverage reward: [0.98686237]\ncosine similarity 1.0\neuclidian norm  0.0\n\n\n\n\n\n\n\n\n\n\n\nSoftmax agent, beta= 0.1\nmaximum possible reward: 0.9851042878107023\naverage reward: [0.91348264]\ncosine similarity 0.9992727823574249\neuclidian norm  0.008915931500017809\n\n\n\n\n\n\n\n\n\n\n\nUCB1 agent\nmaximum possible reward: 0.9851042878107023\naverage reward: [0.89258379]\ncosine similarity 0.0\neuclidian norm  0.1414213562373095\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperimental stuff:\nBelow are a few agents I wrote for fun.\n\n\nclass softmax_with_exponentiation(agent):\n\n    def __init__(self, arms, play_once=1, beta=1, exp=1):\n        super().__init__(arms, play_once)\n        self.beta = beta\n        self.exp = exp\n\n    def policy(self):\n        temp = np.exp(self.expectations/self.beta)\n        ans = temp / np.sum(temp, axis=0)\n        ans = ans**self.exp\n        ans /= np.sum(ans, axis=0)\n        return ans\n\n\nclass softmax_with_reccurence(agent):\n\n    def __init__(self, arms, play_once=1, beta=1):\n        super().__init__(arms, play_once)\n        self.old_policy = np.ones_like(self.expectations)/self.l\n        self.beta = beta\n\n    def policy(self):\n        temp = np.exp(self.expectations/self.beta)\n        new_policy = temp / np.sum(temp, axis=0)\n\n        result = np.multiply(new_policy, self.old_policy)\n        result /= np.sum(result, axis=0)\n        self.old_policy = result\n\n        return result\n\n\nclass greedy_with_reccurence(agent):\n    # alpha = number &lt; 1; will sum over a number of observations and will keep\n    # osiclating.\n    # alpha = N will allow the algo to converge to an arm, greedy doesn't\n    # really need this, kind of always give one answer.\n\n    def __init__(self, arms, play_once=1, alpha=1):\n        super().__init__(arms, play_once)\n        self.old_policy = np.ones_like(self.expectations)\n        self.alpha = alpha\n\n    def policy(self):\n        new_policy = np.zeros_like(self.expectations)\n        new_policy[np.argmax(self.expectations)] = 1\n\n        new_policy = (1-self.alpha)*new_policy + self.alpha*self.old_policy\n\n        new_policy /= np.sum(new_policy, axis=0)\n        self.old_policy = new_policy\n\n        return new_policy\n\n# class magic(agent):\n#    def __init__(self, arms, play_once=1, exp=1):\n#        super().__init__(arms, play_once)\n#        self.old_policy = np.ones_like(self.expectations)/self.l\n#        self.exp = exp\n#\n#    def policy(self):\n#        new_policy = f(old_policy, g(expectations))"
  },
  {
    "objectID": "posts/about-this-website/index.html",
    "href": "posts/about-this-website/index.html",
    "title": "About this website",
    "section": "",
    "text": "This post is a bit of a meta post about arjunsriva.com\nA lot of my thinking on personal websites has been influenced by other great websites like Gwern‚Äôs, please read this if you‚Äôre interested in it.\nMy goals for this websites are:\n\nTo share things I learned that I personally found useful\nTo provide a playground for me to flesh out rough ideas and speculate.\nTo help me increase the clarity of my thinking by the act of writing something out.\n\non the implementation side my goals are\n\nMake it easy for me to never lose data\n\nmost writing is stored as simple text files, version controlled by git\n\nMake it easy to mix code and prose to explain certain concepts\n\nSome things that I plan on implementing later as I write more are:\n\nAutomatic link archiving to prevent link rot\nConfidence tags to show how certain I am of different things\nBetter sections / tagging to differentiate different kinds of posts, eg. reading list and notes\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/friend-or-foe/index.html",
    "href": "posts/friend-or-foe/index.html",
    "title": "Friend Or Foe",
    "section": "",
    "text": "Co-opeartive and Adversarial Environments\n\n\nThis is a mini interactive ‚Äúgame‚Äù, I made inspired by the paper, without giving too much away, I urge you to play.\nAI Safety Grid Worlds,\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/mental-health-checklist/index.html",
    "href": "posts/mental-health-checklist/index.html",
    "title": "Mental Health Checklists",
    "section": "",
    "text": "Some quizes I made so it‚Äôs easy to keep track of mental health.\n\nBurn‚Äôs depression Checklist use it here\nNovaco‚Äôs Anger Scale use it here\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "An engineer and researcher currently working at Woven By Toyota. My key focus areas are personalization systems, data infrastructure, and machine learning."
  },
  {
    "objectID": "about.html#woven-by-toyota",
    "href": "about.html#woven-by-toyota",
    "title": "About",
    "section": "Woven By Toyota",
    "text": "Woven By Toyota\nAt Woven, I lead multiple projects in data infrastructure, for storage (operational stores, data warehouse) and processing (ETL pipelines, scheduling, collaborative workspaces). I also developed machine learning systems for things like adaptive assessments, and course recommendation systems as one of the founding engineers of MS1, a startup(ish) focused on talent management."
  },
  {
    "objectID": "about.html#bookmyshow",
    "href": "about.html#bookmyshow",
    "title": "About",
    "section": "BookMyShow",
    "text": "BookMyShow\nPreviously, at BookMyShow, I worked on the development of real-time data pipelines for discovery and personalization systems, helping millions of users find entertainment experiences."
  },
  {
    "objectID": "podcast/podcasts/2109.10665/index.html",
    "href": "podcast/podcasts/2109.10665/index.html",
    "title": "Survey on reinforcement learning in reccomender systems",
    "section": "",
    "text": "Goes over some of the different places RL can be used in RecSys.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2406.12214/index.html",
    "href": "podcast/podcasts/2406.12214/index.html",
    "title": "Robustness Evaluation of HD Map Constructors under Sensor Corruptions for Autonomous Driving",
    "section": "",
    "text": "The paper focuses on evaluating the robustness of HD map constructors under various sensor corruptions using a comprehensive benchmark called MapBench. It highlights the vulnerability of existing methods to real-world challenges and suggests the importance of advanced data augmentation techniques and new network architectures to enhance robustness for autonomous driving applications.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/1609.09106/index.html",
    "href": "podcast/podcasts/1609.09106/index.html",
    "title": "Hyper Networks: A Novel Approach to Learning Weights in Deep Neural Networks",
    "section": "",
    "text": "The key takeaways for engineers/specialists are: Hyper Networks introduce a meta-network (hypernetwork) that learns to generate weight structures for deep neural networks, providing flexibility and efficiency. Dynamic hypernetworks allow weights to adapt to input sequences, improving performance on sequential tasks. End-to-end training of hypernetworks with the main network leads to collaborative optimization and comparable or better performance with fewer parameters.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2002.11252/index.html",
    "href": "podcast/podcasts/2002.11252/index.html",
    "title": "AutoEmb Automated Embedding Dimensionality Searchg in Streaming Recommendations",
    "section": "",
    "text": "AutoEmb is about using different lenghts of embedding vectors for different items, use less memory + potentially learn more robust stuff for items with less data, and learn more nuanced stuff for popular items.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2304.08069/index.html",
    "href": "podcast/podcasts/2304.08069/index.html",
    "title": "RT-DETR: Real-Time Object Detection with Transformer",
    "section": "",
    "text": "RT-DETR is a groundbreaking end-to-end real-time object detector based on Transformers that combines the speed of YOLO with the accuracy of DETR. Key takeaways for engineers include the efficient hybrid encoder approach, which improves multi-scale feature interactions, and the uncertainty-minimal query selection scheme, enhancing accuracy in both classification and localization. Despite outperforming traditional CNN-based methods, RT-DETR faces challenges in detecting small objects, prompting future research directions like knowledge distillation.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2310.08370/index.html",
    "href": "podcast/podcasts/2310.08370/index.html",
    "title": "UniPAD: A Universal Pre-training Paradigm for Autonomous Driving",
    "section": "",
    "text": "UniPAD is a novel self-supervised learning framework designed for autonomous driving, focusing on learning effective representations from 3D data such as LiDAR point clouds and multi-view images. The framework consists of a modality-specific encoder, a mask generator for challenging training, a unified 3D volumetric representation, and a neural rendering decoder. UniPAD showed promising results in improving performance on tasks like 3D object detection and semantic segmentation, outperforming other pre-training methods and offering potential for broader applications beyond autonomous driving.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2006.06373/index.html",
    "href": "podcast/podcasts/2006.06373/index.html",
    "title": "The limits to learning a diffusion model",
    "section": "",
    "text": "Don‚Äôt be confused by the title, diffusion here is not referring to diffusion as we use it today in context of image generation process, but more about modelling diffusive processes (like virus spread)\n  This paper answers the question about ‚Äòhow much data do we need, before we can figure out the final affected value‚Äô turns out this is a lot more thant people expect.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2310.13810/index.html",
    "href": "podcast/podcasts/2310.13810/index.html",
    "title": "A Better Match for Drivers and Riders Reinforcement Learning at Lyft",
    "section": "",
    "text": "The paper demonstrates the successful application of reinforcement learning to improve the efficiency of driver-rider matching in ride-sharing platforms. The use of online RL allows for real-time adaptation, resulting in decreased wait times for riders, increased earnings for drivers, and overall higher user satisfaction. The research paves the way for more intelligent systems in the ride-sharing industry, with potential for further optimization and expansion into various other aspects of the ecosystem.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2306.00248v1/index.html",
    "href": "podcast/podcasts/2306.00248v1/index.html",
    "title": "TransAct Transformer-based Realtime User Action Model for Recommendation at Pinterest",
    "section": "",
    "text": "Pinterest home feed reccomendation system. Needs to react to both long term interests + short term (even single session only) interests.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/1806.09055/index.html",
    "href": "podcast/podcasts/1806.09055/index.html",
    "title": "DARTS: Differentiable Architecture Search",
    "section": "",
    "text": "Key takeaways for engineers/specialists: DARTS introduces a continuous relaxation approach to architecture search, leveraging gradient descent for efficient optimization. It achieves state-of-the-art results on image classification and language modeling tasks with significantly less computational cost. Challenges include the gap between continuous and discrete architecture representation, computational cost of second-order approximation, and sensitivity to hyperparameters.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2211.02131/index.html",
    "href": "podcast/podcasts/2211.02131/index.html",
    "title": "SafePathNet: Learning a Distribution of Trajectories for Safe and Comfortable Autonomous Driving",
    "section": "",
    "text": "SafePathNet introduces a novel approach that models the distribution of future trajectories for both the self-driving vehicle and other road agents using a unified neural network architecture. By incorporating a ‚ÄòMixture of Experts‚Äô framework, the model can learn diverse driving strategies and prioritize safety in real-time decision-making. The use of Transformer networks and imitation learning further enhances the model‚Äôs ability to handle complex and unpredictable driving scenarios.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2212.07677/index.html",
    "href": "podcast/podcasts/2212.07677/index.html",
    "title": "Unraveling the Connection between In-Context Learning and Gradient Descent in Transformers",
    "section": "",
    "text": "On how Transformers leverage in-context learning mechanisms through gradient descent, enabling them to adapt to new tasks efficiently. Understanding this connection can help improve model generalization, enhance few-shot learning capabilities, and potentially lead to the development of more intelligent and adaptable AI systems.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2406.08691/index.html",
    "href": "podcast/podcasts/2406.08691/index.html",
    "title": "Unsupervised Occupancy Fields for Perception and Forecasting",
    "section": "",
    "text": "The paper ‚ÄòUnO: Unsupervised Occupancy Fields for Perception and Forecasting‚Äô introduces a novel approach to perception and forecasting in self-driving vehicles using unsupervised learning from raw LiDAR data. By leveraging occupancy fields and deformable attention mechanisms, the UnO model outperformed existing methods on point cloud forecasting and semantic occupancy tasks, showing promise for enhancing the robustness and safety of autonomous systems especially in scenarios where labeled data is limited or rare events occur.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2112.04426/index.html",
    "href": "podcast/podcasts/2112.04426/index.html",
    "title": "Retrieval-Enhanced Transformers (RETRO): A Semi-Parametric Approach to Enhance Performance of Large Language Models",
    "section": "",
    "text": "The paper introduces the RETRO model, which leverages retrieval from a massive text database to enhance large language model performance without increasing model size. Key takeaways include the benefits of linear time complexity for retrieval, the use of frozen BERT for efficient retrieval, and the importance of addressing test set leakage in evaluation.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2402.12289/index.html",
    "href": "podcast/podcasts/2402.12289/index.html",
    "title": "DriveVLM: Vision-Language Models for Autonomous Driving in Urban Environments",
    "section": "",
    "text": "The paper introduces DriveVLM, a system that leverages Vision-Language Models for scene understanding in autonomous driving. It comprises modules for Scene Description, Scene Analysis, and Hierarchical Planning to handle complex driving scenarios. DriveVLM outperformed other models in handling uncommon objects and unexpected events, while DriveVLM-Dual achieved state-of-the-art performance in planning tasks, showing promise for future improvements in autonomous driving.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2103.01775/index.html",
    "href": "podcast/podcasts/2103.01775/index.html",
    "title": "No-Transaction Band Network A Neural Network Architecture for Efficient Deep Hedging",
    "section": "",
    "text": "The paper introduces a deep hedging approach using neural networks to optimize hedging strategies for derivatives in imperfect markets. The key takeaway is the development of the ‚Äòno-transaction band network‚Äô to address action dependence and improve efficiency in hedging, showcasing superior performance compared to traditional methods in terms of expected utility and price efficiency, and faster training. Future research focuses on addressing limitations such as non-linear transaction costs and discontinuous payoffs, as well as challenges in data availability and model explainability for real-world applications.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "til/index.html",
    "href": "til/index.html",
    "title": "TIL: Today I Learned",
    "section": "",
    "text": "A collection of links, notes, snippets on things I am reading, watching.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "podcast/podcasts/2407.01781/index.html",
    "href": "podcast/podcasts/2407.01781/index.html",
    "title": "ùëìVDB: A Deep-Learning Framework for Sparse, Large-Scale, and High-Performance Spatial Intelligence",
    "section": "",
    "text": "Engineers and specialists can benefit from ùëìVDB by leveraging its memory-efficient IndexGrid structure and specialized convolution kernels optimized for different sparsity patterns. The framework provides significant speed and memory efficiency improvements over existing frameworks, enabling more effective handling of large-scale, sparse 3D datasets in deep learning applications.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2406.07550/index.html",
    "href": "podcast/podcasts/2406.07550/index.html",
    "title": "TiTok: A Transformer-based 1D Tokenization Approach for Image Generation",
    "section": "",
    "text": "TiTok introduces a novel 1D tokenization method for image generation, enabling the representation of images with significantly fewer tokens while maintaining or surpassing the performance of existing 2D grid-based methods. The approach leverages a Vision Transformer architecture, two-stage training with proxy codes, and achieves remarkable speedup in training and inference. The research opens up new possibilities for efficient and high-quality image generation, with implications for various applications in computer vision and beyond.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2304.11277/index.html",
    "href": "podcast/podcasts/2304.11277/index.html",
    "title": "PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel",
    "section": "",
    "text": "FSDP addresses memory capacity challenges by sharding parameters across devices, employs communication optimizations to enhance efficiency, includes a rate limiter feature to control memory impact, offers user-friendly APIs for easy integration, achieved promising results on large models, enables broader applications in various domains, faces challenges in mathematical equivalence and handling shared parameters, and has potential research directions in adaptive sharding strategies, new communication primitives, and combining with other parallelism paradigms.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2310.01801/index.html",
    "href": "podcast/podcasts/2310.01801/index.html",
    "title": "Models tell you what to discard",
    "section": "",
    "text": "This paper introduces FastGen, a novel method that uses lightweight model profiling and adaptive key-value caching to significantly reduce memory footprint without noticeable quality loss.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2407.02945/index.html",
    "href": "podcast/podcasts/2407.02945/index.html",
    "title": "Extrapolated View Synthesis for Urban Scene Reconstruction",
    "section": "",
    "text": "The paper introduces Extrapolated View Synthesis (EVS) for urban scene reconstruction, addressing limitations in current methods by using 3D Gaussian Splatting for scene representation. By incorporating surface normal information and leveraging diffusion models, the proposed method, VEGS, outperforms existing approaches in generating visually realistic and accurate renderings for urban environments.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2406.17345/index.html",
    "href": "podcast/podcasts/2406.17345/index.html",
    "title": "NerfBaselines: A Framework for Standardized Evaluation of Novel View Synthesis Methods in Computer Vision",
    "section": "",
    "text": "NerfBaselines addresses the inconsistent evaluation protocols in comparing novel view synthesis methods by providing a unified interface, ensuring reproducibility through containerization, and standardizing the evaluation protocol. By enabling the sharing of pre-trained checkpoints, it reduces computational costs and environmental impact. However, it relies on methods exposing the same interface and future directions involve exploring advanced evaluation metrics and addressing the computational cost of training.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2401.10241/index.html",
    "href": "podcast/podcasts/2401.10241/index.html",
    "title": "Zero Bubble Pipeline Parallelism",
    "section": "",
    "text": "Core idea is think about backward pass into two flows, one to compute grad wrt to parameters, and one to compute grad wrt to output of last layer, schedule so that you are always working instead of waiting (bubble).\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2205.14135/index.html",
    "href": "podcast/podcasts/2205.14135/index.html",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness",
    "section": "",
    "text": "FlashAttention is a novel algorithm that addresses the efficiency of Transformer models by improving speed and memory efficiency through IO-awareness. It reduces the number of memory accesses by dividing data into smaller blocks and loading them into fast memory, achieving practical speedups and enabling training on longer sequences. The algorithm also incorporates recomputation during the backward pass to minimize memory usage, delivering significant improvements in training large models like BERT and GPT-2.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2303.04129/index.html",
    "href": "podcast/podcasts/2303.04129/index.html",
    "title": "Foundation Models in Decision Making: Roles, Challenges, and Opportunities",
    "section": "",
    "text": "The paper proposes a framework for understanding the various roles of foundation models in decision making, including conditional generative models, representation learners, and interactive agents. Key takeaways include the use of foundation models for behavioral priors, world modeling, and generalization of knowledge across tasks and environments.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2212.10156/index.html",
    "href": "podcast/podcasts/2212.10156/index.html",
    "title": "Planning-Oriented Autonomous Driving",
    "section": "",
    "text": "The paper introduces UniAD, a planning-oriented framework for autonomous driving that focuses on integrating perception, prediction, and planning tasks to optimize for safe and efficient driving. UniAD outperforms existing state-of-the-art methods in motion forecasting, occupancy prediction, and planning, showcasing the benefits of joint optimization and query-based communication between modules. Key challenges for future research include addressing computational complexity, handling long-tail scenarios, and exploring additional tasks like depth estimation and behavior prediction.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2407.02524/index.html",
    "href": "podcast/podcasts/2407.02524/index.html",
    "title": "Training Large Language Models for Compiler Optimization",
    "section": "",
    "text": "The research paper discusses the development of LLM Compiler, a model specifically trained on compiler IRs and assembly code for optimizing code efficiently. This approach outperforms traditional techniques and existing LLMs in tasks like flag tuning and disassembly, showing potential for automating and improving the optimization process in software engineering.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2111.15397/index.html",
    "href": "podcast/podcasts/2111.15397/index.html",
    "title": "NeuralProphet Explainable Forecasting at Scale",
    "section": "",
    "text": "‚ÄòSuccessor‚Äô of Prophet (by facebook) for time series modelling.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2406.11066/index.html",
    "href": "podcast/podcasts/2406.11066/index.html",
    "title": "Metadata-based Color Harmonization for Multi-camera Surround View Systems",
    "section": "",
    "text": "The paper introduces a metadata-based approach to address color inconsistencies in multi-camera surround view systems, crucial for accurate perception in autonomous driving. The method significantly outperforms traditional techniques in visual quality and runtime, making it more efficient and robust for real-time applications.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/1910.02054/index.html",
    "href": "podcast/podcasts/1910.02054/index.html",
    "title": "ZeRO Memory Optimizations: Toward Training Trillion Parameter Models",
    "section": "",
    "text": "The paper introduces ZeRO, a novel approach to optimize memory usage when training massive language models. ZeRO-DP and ZeRO-R components effectively reduce memory redundancy and allow for training models with up to 170 billion parameters efficiently. The technique shows superlinear scalability, user-friendly implementation, and has the potential to democratize large model training in AI research.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/podcasts/2403.03507/index.html",
    "href": "podcast/podcasts/2403.03507/index.html",
    "title": "Gradient Low-Rank Projection (GaLore): Revolutionizing Memory-Efficient LLM Training",
    "section": "",
    "text": "GaLore offers a breakthrough in memory-efficient LLM training by reducing memory usage significantly while achieving performance comparable to full-rank training. It enables training of large models on limited hardware resources, democratizing LLM research and development. Future research directions include applying GaLore to various model architectures, enhancing memory efficiency further, and exploring elastic data distributed training using consumer-grade hardware.\n  \n  \n\n\n\n  \n    Listen to the Podcast\n    \n      \n        \n        Your browser does not support the audio element.\n      \n    \n\n    \n      Related Links\n      \n        \n        Read transcript\n        Read original paper"
  },
  {
    "objectID": "podcast/index.html",
    "href": "podcast/index.html",
    "title": "Podcast",
    "section": "",
    "text": "I love Arxiv, but often find myself with pockets of time when I can‚Äôt sit down and read. This podcast bridges that gap, offering bite-sized explorations of individual papers.\nA few things to note:\n\nThe voices you‚Äôll hear are AI-generated, not real people (though names from papers might appear).\nWhile we strive for accuracy, these are complex topics. Our current AI systems aren‚Äôt perfect, so approach with a critical mind.\nConsider this a starting point. For deeper understanding, always refer to the original paper.\nThe papers featured are ones I‚Äôm personally interested in or have been wanting to read. It‚Äôs a curated selection based on my interests.\n\nThis podcast aims to spark curiosity and make cutting-edge research more accessible. It‚Äôs perfect for those moments when you want to learn but can‚Äôt dive into a full paper.\nEnjoy the exploration of ideas, and let it fuel your interest in further reading!"
  },
  {
    "objectID": "podcast/index.html#byte-sized-breakthroughs-podcast",
    "href": "podcast/index.html#byte-sized-breakthroughs-podcast",
    "title": "Podcast",
    "section": "",
    "text": "I love Arxiv, but often find myself with pockets of time when I can‚Äôt sit down and read. This podcast bridges that gap, offering bite-sized explorations of individual papers.\nA few things to note:\n\nThe voices you‚Äôll hear are AI-generated, not real people (though names from papers might appear).\nWhile we strive for accuracy, these are complex topics. Our current AI systems aren‚Äôt perfect, so approach with a critical mind.\nConsider this a starting point. For deeper understanding, always refer to the original paper.\nThe papers featured are ones I‚Äôm personally interested in or have been wanting to read. It‚Äôs a curated selection based on my interests.\n\nThis podcast aims to spark curiosity and make cutting-edge research more accessible. It‚Äôs perfect for those moments when you want to learn but can‚Äôt dive into a full paper.\nEnjoy the exploration of ideas, and let it fuel your interest in further reading!"
  },
  {
    "objectID": "podcast/index.html#listen-everywhere",
    "href": "podcast/index.html#listen-everywhere",
    "title": "Podcast",
    "section": "Listen everywhere",
    "text": "Listen everywhere"
  },
  {
    "objectID": "podcast/index.html#the-team",
    "href": "podcast/index.html#the-team",
    "title": "Podcast",
    "section": "The Team",
    "text": "The Team\n\nAlex Askwell: Our curious and knowledgeable moderator, always ready with the right questions to guide our exploration.\nDr.¬†Paige Turner: Our lead researcher and paper expert, diving deep into the methods and results.\nProf.¬†Wyd Spectrum: Our field expert, providing broader context and critical insights.\n\nJoin them as they break down complex research into byte-sized breakthroughs!"
  },
  {
    "objectID": "posts/state-of-reading/index.html",
    "href": "posts/state-of-reading/index.html",
    "title": "The state of reading in 2018 and beyond.",
    "section": "",
    "text": "Audio books are seeing a resurgence, because of companies like Audible.\nText to speech is good, and is getting better .\nWireless Bluetooth earphones are becoming common place, the increase in convenience and battery life allows people to have them on longer.\nUnlike content that you have to watch/read, you can work on other stuff while you listen.\nI see a time where we can listen to most of the things we read.\nCreates a whole new kind of medium.\nNews, blog posts and Stories most affected.\nMost of the speech generated by machines.\nMost of the classic texts available for free on the internet.\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/game-of-thrones-quiz/index.html",
    "href": "posts/game-of-thrones-quiz/index.html",
    "title": "Game Of Thrones quiz",
    "section": "",
    "text": "Game Of Thrones Quiz\nThis quiz was created as part of cultural week, right as Game of Thrones season 7 ended.\nIt is broken into 3 seperate rounds"
  },
  {
    "objectID": "posts/game-of-thrones-quiz/index.html#first-round",
    "href": "posts/game-of-thrones-quiz/index.html#first-round",
    "title": "Game Of Thrones quiz",
    "section": "First round",
    "text": "First round\nQuestions\nAnswers"
  },
  {
    "objectID": "posts/game-of-thrones-quiz/index.html#second-round",
    "href": "posts/game-of-thrones-quiz/index.html#second-round",
    "title": "Game Of Thrones quiz",
    "section": "Second round",
    "text": "Second round\nSlides\nvideo for question 1\nmusic for question 2\nvideo for question 3"
  },
  {
    "objectID": "posts/game-of-thrones-quiz/index.html#third-round",
    "href": "posts/game-of-thrones-quiz/index.html#third-round",
    "title": "Game Of Thrones quiz",
    "section": "Third round",
    "text": "Third round\nConnect"
  },
  {
    "objectID": "posts/course-schedule-generator/index.html",
    "href": "posts/course-schedule-generator/index.html",
    "title": "Course Schedule Generator",
    "section": "",
    "text": "A website which allows students of IIT Indore to add courses they are interested in to their calendar.\nI was tired of doing this manually every time.\nUse it here\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/harry-potter-quiz/index.html",
    "href": "posts/harry-potter-quiz/index.html",
    "title": "Harry Potter quiz",
    "section": "",
    "text": "Pottermania 2018\n\n\nThe goal of the is to be something easy that anybody with little experience in quizzing can take part in. created with Bitan, and Keyur as part of Quiz club.\n\nQuestions\nGet the questions.\nGet the video for question number 14\nGet the Music for question number 20\n\n\nAnswers\nGet the answers.\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/newbie-quiz/index.html",
    "href": "posts/newbie-quiz/index.html",
    "title": "Newbie quiz",
    "section": "",
    "text": "Newbie Quiz\n\n\nIndraneel and I had prepared this quiz as a way of introducting quizzing to new people and narrowing down potential recruits. The quiz covers a broad range of topics, from pop culture, sports, technology, politics\nLots of fun!\n\nQuestions\nGet the questions.\n\n\nAnswers\nGet the answers.\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/learning-machine-learning/index.html",
    "href": "posts/learning-machine-learning/index.html",
    "title": "Learning Machine Learning",
    "section": "",
    "text": "This post will talk about resources for how I‚Äôm going about learning machine learning.\n\nBooks\n\n‚ÄúHands-On Machine Learning with Scikit-Learn and TensorFlow‚Äù by Aur√©lien G√©ron\n‚ÄúDeep Learning‚Äù by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n‚ÄúThe Elements of Statistical Learning‚Äù by Trevor Hastie, Robert Tibshirani, and Jerome Friedman\n\n\n\nBlogs\n\nDistill.pub: Clear, interactive explanations of machine learning concepts\nSebastian Ruder‚Äôs blog: In-depth articles on NLP and deep learning\nAndrej Karpathy‚Äôs blog: Excellent posts on deep learning\n\n\n\nPodcasts\nThese podcasts are amazing,and what got me interested in the first place. Get a podcast app, I love podcast addict (android). Some awesome podcasts:\n\nPartially Derivative\nLinear Digressions\nData Skeptic\n\nSome that are supposed to be good but never tried:\n\nNot so standard deviations\nData science at home\nTalking machines\n\n\n\nOnline Courses\nA few awesome courses.\n\nAndrew Ng Coursera\nA good first course, which teaches you bottom up, from basics to advanced techniques. Matlab/Octave.\nFast.ai\nA course which aims to teach by coding, and takes a top down approach.\nCS231n: Convolutional Neural Networks for Visual Recognition While focused on computer vision, this Stanford course provides an excellent introduction to deep learning concepts.\n\n\n\nStaying Up-to-Date\nOne of the best things about the machine learning field is how much work happens in the open.\nMany researchers publish their work on arXiv months or even years before it appears in journals or at conferences. Following key researchers and institutions on Twitter is an excellent way to stay informed about the latest developments as they happen.\nSome great accounts to follow: @goodfellow_ian, @ylecun, @karpathy, @gwern.\nDon‚Äôt be afraid of reading arXiv papers, they might seem intimidating in the beginning but they get easier over time.\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html",
    "href": "posts/exerimentations-platforms/index.html",
    "title": "Experimentation Platforms",
    "section": "",
    "text": "Trustworthy Online Controlled Experiments"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#books",
    "href": "posts/exerimentations-platforms/index.html#books",
    "title": "Experimentation Platforms",
    "section": "",
    "text": "Trustworthy Online Controlled Experiments"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#resources",
    "href": "posts/exerimentations-platforms/index.html#resources",
    "title": "Experimentation Platforms",
    "section": "Resources",
    "text": "Resources\n\nTop Challenges from the first Practical Online Controlled Experiments Summit\nA/B Testing Pitfalls: Getting Numbers You Can Trust is Hard\nUSF Business Analytics Forum - Ron Kohavi\nA/B Testing at Scale: Accelerating Software Innovation\nTrustworthy Online Controlled Experiments at Large Scale\nAlways Valid Inference: Continuous Monitoring of A/B Tests"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#companies",
    "href": "posts/exerimentations-platforms/index.html#companies",
    "title": "Experimentation Platforms",
    "section": "Companies",
    "text": "Companies\n\nNetflix\n\nNetflix Articles tagged Experimentation\nIt‚Äôs All A/Bout Testing: The Netflix Experimentation Platform\nReimagining Experimentation Analysis at Netflix\nSuccess stories from a democratized experimentation platform\nKey Challenges with Quasi Experiments at Netflix\nData Compression for Large-Scale Streaming Experimentation\nPage Simulation for Better Offline Metrics at Netflix\nStreaming Video Experimentation at Netflix: Visualizing Practical and Statistical Significance\nInnovating Faster on Personalization Algorithms at Netflix Using Interleaving\n\n\n\nMicrosoft\n\nExP Experimentation Platform Accelerating software innovation through trustworthy experimentation\nOnline Experimentation at Microsoft\nExperimentation Platform\nA/B Testing and Covid-19: Data-Driven Decisions in Times of Uncertainty\nPatterns of Trustworthy Experimentation: Pre-Experiment Stage\n\n\n\nTwitter\n\nTwitter experimentation: technical overview\n\n\n\nGoogle\n\nOverlapping Experiment Infrastructure: More, Better, Faster Experimentation\n\n\n\nFacebook\n\nPlanOut is a library and interpreter for designing online experiments.\nAdaptive Experimentation Platform\n\n\n\nSpotify\n\nSpotify‚Äôs New Experimentation Platform part 1\nSpotify‚Äôs New Experimentation Platform part 2\nLarge Scale Experimentation at Spotify\n\n\n\nTinder\n\nPhoenix ‚Äî Tinder‚Äôs Testing Platform, Part ‚Äî I\nPhoenix ‚Äî Tinder‚Äôs Testing Platform ‚Äî Part II\nPhoenix ‚Äî Tinder‚Äôs Testing Platform ‚Äî Part III\n\n\n\nLinkedIn\n\nOur evolution towards T-REX: The prehistory of experimentation infrastructure at LinkedIn\nMaking the LinkedIn experimentation engine 20x faster\n\n\n\nUber\n\nUnder the Hood of Uber‚Äôs Experimentation Platform\nA/B testing at Uber: How we built a BYOM (bring your own metrics) platform\nBuilding an Intelligent Experimentation Platform with Uber Engineering\n\n\n\nAirBnB\n\n4 Principles for Making Experimentation Count\nScaling Airbnb‚Äôs Experimentation Platform\nExperiment Reporting Framework\n\n\n\nInstagram\n\nLessons Learned at Instagram Stories and Feed Machine Learning\n\n\n\nGo-Jek\n\nIntroducing Litmus: GOJEK‚Äôs Own Experimentation Platform\n\n\n\nInstaCart\n\nRandomized, controlled experiments and multivariate regression are used to continuously improve the grocery delivery engine\n\n\n\nPintrest\n\nBuilding Pinterest‚Äôs A/B testing platform"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#conferences",
    "href": "posts/exerimentations-platforms/index.html#conferences",
    "title": "Experimentation Platforms",
    "section": "Conferences",
    "text": "Conferences\n\nExperimentation Culture Awards"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#sass-solutions",
    "href": "posts/exerimentations-platforms/index.html#sass-solutions",
    "title": "Experimentation Platforms",
    "section": "SASS solutions",
    "text": "SASS solutions\n\nSplit.io\nOptimizely"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#when-you-cant-run-ab-tests",
    "href": "posts/exerimentations-platforms/index.html#when-you-cant-run-ab-tests",
    "title": "Experimentation Platforms",
    "section": "When you can‚Äôt run A/B Tests",
    "text": "When you can‚Äôt run A/B Tests\n\nQuasi Experimentation at Netflix\nKey Challenges with Quasi Experiments at Netflix\nMostly Harmless Econometrics: An Empiricist‚Äôs Companion"
  },
  {
    "objectID": "posts/exerimentations-platforms/index.html#notes",
    "href": "posts/exerimentations-platforms/index.html#notes",
    "title": "Experimentation Platforms",
    "section": "Notes",
    "text": "Notes\n\n2020 CODE@MIT Experimentation platforms\n\nGaussian processes\nMulti touch attributions\nHeterogenous treatment effect\nInteraction effects\nOverlapping experiments\nWhat are potential over evaluation criteria ?\nWhat are good guardrail metrics ?\nrun A/A tests.\n\nCanary Deploys by using Experimentation platform to tell when you break guard rail metrics"
  }
]