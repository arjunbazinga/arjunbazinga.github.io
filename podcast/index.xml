<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Arjun Srivastava</title>
<link>https://www.arjunsriva.com/podcast/</link>
<atom:link href="https://www.arjunsriva.com/podcast/index.xml" rel="self" type="application/rss+xml"/>
<description>AI-generated podcasts discussing the latest research.</description>
<generator>quarto-1.5.56</generator>
<lastBuildDate>Wed, 24 Jul 2024 00:00:00 GMT</lastBuildDate>
<item>
  <title>Unraveling the Connection between In-Context Learning and Gradient Descent in Transformers</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2212.07677/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>On how Transformers leverage in-context learning mechanisms through gradient descent, enabling them to adapt to new tasks efficiently. Understanding this connection can help improve model generalization, enhance few-shot learning capabilities, and potentially lead to the development of more intelligent and adaptable AI systems.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2212.07677.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2212.07677.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2212.07677.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2212.07677">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Natural Language Processing</category>
  <category>Deep Learning</category>
  <category>Explainable AI</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2212.07677/</guid>
  <pubDate>Wed, 24 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Gradient Low-Rank Projection (GaLore): Revolutionizing Memory-Efficient LLM Training</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2403.03507/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>GaLore offers a breakthrough in memory-efficient LLM training by reducing memory usage significantly while achieving performance comparable to full-rank training. It enables training of large models on limited hardware resources, democratizing LLM research and development. Future research directions include applying GaLore to various model architectures, enhancing memory efficiency further, and exploring elastic data distributed training using consumer-grade hardware.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2403.03507.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2403.03507.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2403.03507.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2403.03507">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Natural Language Processing</category>
  <category>Optimization</category>
  <category>Systems and Performance</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2403.03507/</guid>
  <pubDate>Wed, 24 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Retrieval-Enhanced Transformers (RETRO): A Semi-Parametric Approach to Enhance Performance of Large Language Models</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2112.04426/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>The paper introduces the RETRO model, which leverages retrieval from a massive text database to enhance large language model performance without increasing model size. Key takeaways include the benefits of linear time complexity for retrieval, the use of frozen BERT for efficient retrieval, and the importance of addressing test set leakage in evaluation.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2112.04426.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2112.04426.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2112.04426.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2112.04426">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Natural Language Processing</category>
  <category>Deep Learning</category>
  <category>Systems and Performance</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2112.04426/</guid>
  <pubDate>Sat, 20 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2304.11277/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>FSDP addresses memory capacity challenges by sharding parameters across devices, employs communication optimizations to enhance efficiency, includes a rate limiter feature to control memory impact, offers user-friendly APIs for easy integration, achieved promising results on large models, enables broader applications in various domains, faces challenges in mathematical equivalence and handling shared parameters, and has potential research directions in adaptive sharding strategies, new communication primitives, and combining with other parallelism paradigms.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2304.11277.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2304.11277.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2304.11277.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2304.11277">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Systems and Performance</category>
  <category>Deep Learning</category>
  <category>Machine Learning</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2304.11277/</guid>
  <pubDate>Sat, 20 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2205.14135/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>FlashAttention is a novel algorithm that addresses the efficiency of Transformer models by improving speed and memory efficiency through IO-awareness. It reduces the number of memory accesses by dividing data into smaller blocks and loading them into fast memory, achieving practical speedups and enabling training on longer sequences. The algorithm also incorporates recomputation during the backward pass to minimize memory usage, delivering significant improvements in training large models like BERT and GPT-2.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2205.14135.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2205.14135.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2205.14135.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2205.14135">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Deep Learning</category>
  <category>Transformers</category>
  <category>Systems and Performance</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2205.14135/</guid>
  <pubDate>Sat, 20 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Foundation Models in Decision Making: Roles, Challenges, and Opportunities</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2303.04129/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>The paper proposes a framework for understanding the various roles of foundation models in decision making, including conditional generative models, representation learners, and interactive agents. Key takeaways include the use of foundation models for behavioral priors, world modeling, and generalization of knowledge across tasks and environments.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2303.04129.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2303.04129.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2303.04129.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2303.04129">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Artificial Intelligence</category>
  <category>Machine Learning</category>
  <category>Explainable AI</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2303.04129/</guid>
  <pubDate>Sat, 20 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>TiTok: A Transformer-based 1D Tokenization Approach for Image Generation</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2406.07550/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>TiTok introduces a novel 1D tokenization method for image generation, enabling the representation of images with significantly fewer tokens while maintaining or surpassing the performance of existing 2D grid-based methods. The approach leverages a Vision Transformer architecture, two-stage training with proxy codes, and achieves remarkable speedup in training and inference. The research opens up new possibilities for efficient and high-quality image generation, with implications for various applications in computer vision and beyond.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2406.07550.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2406.07550.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2406.07550.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2406.07550">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Generative Models</category>
  <category>Computer Vision</category>
  <category>Transformers</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2406.07550/</guid>
  <pubDate>Fri, 19 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>DARTS: Differentiable Architecture Search</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/1806.09055/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>Key takeaways for engineers/specialists: DARTS introduces a continuous relaxation approach to architecture search, leveraging gradient descent for efficient optimization. It achieves state-of-the-art results on image classification and language modeling tasks with significantly less computational cost. Challenges include the gap between continuous and discrete architecture representation, computational cost of second-order approximation, and sensitivity to hyperparameters.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/1806.09055.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/1806.09055.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/1806.09055.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/1806.09055">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Deep Learning</category>
  <category>Optimization</category>
  <category>Machine Learning</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/1806.09055/</guid>
  <pubDate>Fri, 19 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Hyper Networks: A Novel Approach to Learning Weights in Deep Neural Networks</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/1609.09106/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>The key takeaways for engineers/specialists are: Hyper Networks introduce a meta-network (hypernetwork) that learns to generate weight structures for deep neural networks, providing flexibility and efficiency. Dynamic hypernetworks allow weights to adapt to input sequences, improving performance on sequential tasks. End-to-end training of hypernetworks with the main network leads to collaborative optimization and comparable or better performance with fewer parameters.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/1609.09106.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/1609.09106.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/1609.09106.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/1609.09106">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Deep Learning</category>
  <category>Machine Learning</category>
  <category>Neural Networks</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/1609.09106/</guid>
  <pubDate>Fri, 19 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>DriveVLM: Vision-Language Models for Autonomous Driving in Urban Environments</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2402.12289/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>The paper introduces DriveVLM, a system that leverages Vision-Language Models for scene understanding in autonomous driving. It comprises modules for Scene Description, Scene Analysis, and Hierarchical Planning to handle complex driving scenarios. DriveVLM outperformed other models in handling uncommon objects and unexpected events, while DriveVLM-Dual achieved state-of-the-art performance in planning tasks, showing promise for future improvements in autonomous driving.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2402.12289.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2402.12289.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2402.12289.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2402.12289">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Autonomous Driving</category>
  <category>Computer Vision</category>
  <category>Multimodal AI</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2402.12289/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Unsupervised Occupancy Fields for Perception and Forecasting</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2406.08691/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>The paper ‘UnO: Unsupervised Occupancy Fields for Perception and Forecasting’ introduces a novel approach to perception and forecasting in self-driving vehicles using unsupervised learning from raw LiDAR data. By leveraging occupancy fields and deformable attention mechanisms, the UnO model outperformed existing methods on point cloud forecasting and semantic occupancy tasks, showing promise for enhancing the robustness and safety of autonomous systems especially in scenarios where labeled data is limited or rare events occur.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2406.08691.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2406.08691.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2406.08691.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2406.08691">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Computer Vision</category>
  <category>Machine Learning</category>
  <category>Autonomous Driving</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2406.08691/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Extrapolated View Synthesis for Urban Scene Reconstruction</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2407.02945/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>The paper introduces Extrapolated View Synthesis (EVS) for urban scene reconstruction, addressing limitations in current methods by using 3D Gaussian Splatting for scene representation. By incorporating surface normal information and leveraging diffusion models, the proposed method, VEGS, outperforms existing approaches in generating visually realistic and accurate renderings for urban environments.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2407.02945.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2407.02945.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2407.02945.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2407.02945">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>3D Vision</category>
  <category>Computer Vision</category>
  <category>Generative Models</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2407.02945/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>SafePathNet: Learning a Distribution of Trajectories for Safe and Comfortable Autonomous Driving</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2211.02131/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>SafePathNet introduces a novel approach that models the distribution of future trajectories for both the self-driving vehicle and other road agents using a unified neural network architecture. By incorporating a ‘Mixture of Experts’ framework, the model can learn diverse driving strategies and prioritize safety in real-time decision-making. The use of Transformer networks and imitation learning further enhances the model’s ability to handle complex and unpredictable driving scenarios.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2211.02131.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2211.02131.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2211.02131.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2211.02131">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Autonomous Driving</category>
  <category>AI Safety</category>
  <category>Machine Learning</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2211.02131/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>NerfBaselines: A Framework for Standardized Evaluation of Novel View Synthesis Methods in Computer Vision</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2406.17345/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>NerfBaselines addresses the inconsistent evaluation protocols in comparing novel view synthesis methods by providing a unified interface, ensuring reproducibility through containerization, and standardizing the evaluation protocol. By enabling the sharing of pre-trained checkpoints, it reduces computational costs and environmental impact. However, it relies on methods exposing the same interface and future directions involve exploring advanced evaluation metrics and addressing the computational cost of training.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2406.17345.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2406.17345.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2406.17345.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2406.17345">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>3D Vision</category>
  <category>Computer Vision</category>
  <category>Systems and Performance</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2406.17345/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Planning-Oriented Autonomous Driving</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2212.10156/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>The paper introduces UniAD, a planning-oriented framework for autonomous driving that focuses on integrating perception, prediction, and planning tasks to optimize for safe and efficient driving. UniAD outperforms existing state-of-the-art methods in motion forecasting, occupancy prediction, and planning, showcasing the benefits of joint optimization and query-based communication between modules. Key challenges for future research include addressing computational complexity, handling long-tail scenarios, and exploring additional tasks like depth estimation and behavior prediction.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2212.10156.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2212.10156.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2212.10156.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2212.10156">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Autonomous Driving</category>
  <category>Artificial Intelligence</category>
  <category>Machine Learning</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2212.10156/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>UniPAD: A Universal Pre-training Paradigm for Autonomous Driving</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2310.08370/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>UniPAD is a novel self-supervised learning framework designed for autonomous driving, focusing on learning effective representations from 3D data such as LiDAR point clouds and multi-view images. The framework consists of a modality-specific encoder, a mask generator for challenging training, a unified 3D volumetric representation, and a neural rendering decoder. UniPAD showed promising results in improving performance on tasks like 3D object detection and semantic segmentation, outperforming other pre-training methods and offering potential for broader applications beyond autonomous driving.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2310.08370.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2310.08370.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2310.08370.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2310.08370">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Autonomous Driving</category>
  <category>Deep Learning</category>
  <category>Computer Vision</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2310.08370/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Training Large Language Models for Compiler Optimization</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2407.02524/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>The research paper discusses the development of LLM Compiler, a model specifically trained on compiler IRs and assembly code for optimizing code efficiently. This approach outperforms traditional techniques and existing LLMs in tasks like flag tuning and disassembly, showing potential for automating and improving the optimization process in software engineering.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2407.02524.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2407.02524.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2407.02524.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2407.02524">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Natural Language Processing</category>
  <category>Systems and Performance</category>
  <category>AI for Science</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2407.02524/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>RT-DETR: Real-Time Object Detection with Transformer</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2304.08069/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>RT-DETR is a groundbreaking end-to-end real-time object detector based on Transformers that combines the speed of YOLO with the accuracy of DETR. Key takeaways for engineers include the efficient hybrid encoder approach, which improves multi-scale feature interactions, and the uncertainty-minimal query selection scheme, enhancing accuracy in both classification and localization. Despite outperforming traditional CNN-based methods, RT-DETR faces challenges in detecting small objects, prompting future research directions like knowledge distillation.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2304.08069.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2304.08069.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2304.08069.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2304.08069">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Computer Vision</category>
  <category>Transformers</category>
  <category>Deep Learning</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2304.08069/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Metadata-based Color Harmonization for Multi-camera Surround View Systems</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2406.11066/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>The paper introduces a metadata-based approach to address color inconsistencies in multi-camera surround view systems, crucial for accurate perception in autonomous driving. The method significantly outperforms traditional techniques in visual quality and runtime, making it more efficient and robust for real-time applications.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2406.11066.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2406.11066.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2406.11066.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2406.11066">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Computer Vision</category>
  <category>Autonomous Driving</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2406.11066/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Robustness Evaluation of HD Map Constructors under Sensor Corruptions for Autonomous Driving</title>
  <link>https://www.arjunsriva.com/podcast/podcasts/2406.12214/</link>
  <description><![CDATA[ 
  
    
      

  
  <p>The paper focuses on evaluating the robustness of HD map constructors under various sensor corruptions using a comprehensive benchmark called MapBench. It highlights the vulnerability of existing methods to real-world challenges and suggests the importance of advanced data augmentation techniques and new network architectures to enhance robustness for autonomous driving applications.</p>
  
  



  <div class="podcast-section">
    <h3 class="anchored">Listen to the Podcast</h3>
    <div class="plyr-audio-player">
      <audio id="player" controls="">
        <source src="../../../static/podcast_data/arxiv/audio/2406.12214.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="podcast-links">
      <h4 class="anchored">Related Links</h4>
      <ul>
        <!-- <li><a href="/static/podcast_data/arxiv/audio/2406.12214.mp3" download>Download audio</a></li> -->
        <li><a href="../../../static/podcast_data/arxiv/transcripts/2406.12214.txt">Read transcript</a></li>
        <li><a href="https://arxiv.org/pdf/2406.12214">Read original paper</a></li>
      </ul>
    </div>
  </div>


  <!-- Add Plyr JS -->
  <!-- TODO : remove this network dependency embed script directly as part of build -->
  <script src="https://cdn.plyr.io/3.7.8/plyr.js"></script>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const player = new Plyr('#player', {
        controls: [
          'play-large', 'rewind', 'play', 'fast-forward', 'progress', 'current-time', 'settings', 'airplay', 'download'
        ],
      });
    });
  </script>

     ]]></description>
  <category>Autonomous Driving</category>
  <category>Computer Vision</category>
  <category>AI Safety</category>
  <guid>https://www.arjunsriva.com/podcast/podcasts/2406.12214/</guid>
  <pubDate>Thu, 18 Jul 2024 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
